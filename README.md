I built this application as a hands-on learning project to explore the world of Generative AI. The goal was to create a unified platform to directly interact with and compare the outputs of various large language models (LLMs) side by side.

This project was a deep dive into full-stack development and Gen AI, providing valuable insights into how these powerful models work in a real-world application.

Key Features:-
Multi-Model Chat: Interact with multiple LLMs, including Gemini, LLaMA, Mistral, and Qwen, from a single, streamlined interface.

Side-by-Side Comparison: Evaluate model responses in real-time to observe their unique strengths and weaknesses.

Unified Interface: A clean, minimal UI built with React and Tailwind CSS that consolidates outputs from different APIs.

Tech Stack:-
Frontend: React.js, Tailwind CSS

Backend: Node.js, Express

APIs: Google Gemini API, OpenRouter API

My Learnings:-
Building this project was a significant step in my development journey. I gained practical experience in:

Full-Stack Development: Connecting a modern frontend to a robust backend.

API Integration: Successfully managing and handling requests and responses from multiple third-party APIs.

Generative AI: Gaining a firsthand understanding of different LLMs and their performance in various tasks.

What's Next:-
This is an ongoing project, and I plan to continue building on it by adding new features, including:

Database Support: To store and retrieve chat history.

Orchestration Layer: To intelligently route user queries to the most suitable model.